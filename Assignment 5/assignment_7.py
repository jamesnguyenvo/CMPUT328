# -*- coding: utf-8 -*-
"""Copy of Copy of Assignment_7_student.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Tx9kvC4vbPPAXsj5ZRemmhJT3JVxheSM
"""

import numpy as np
import tensorflow as tf

class TextureImages(object):
    def __init__(self, subset='train', batch_size=64, shuffle=True):
        if subset == 'train':
            images = np.load('train_images.npy')
            masks = np.load('train_masks.npy')
        elif subset == 'test':
            images = np.load('test_images.npy')
            masks = np.load('test_masks.npy')
        else:
            raise NotImplementedError
        self._images = images
        self.images = self._images
        self._masks = masks
        self.masks = self._masks
        self.batch_size = batch_size
        self.num_samples = len(self.images)
        self.shuffle = shuffle
        if self.shuffle:
            self.shuffle_samples()
        self.next_batch_pointer = 0

    def shuffle_samples(self):
        image_indices = np.random.permutation(np.arange(self.num_samples))
        self.images = self._images[image_indices]
        self.masks = self._masks[image_indices]

    def get_next_batch(self):
        num_samples_left = self.num_samples - self.next_batch_pointer
        if num_samples_left >= self.batch_size:
            x_batch = self.images[self.next_batch_pointer:self.next_batch_pointer + self.batch_size]
            y_batch = self.masks[self.next_batch_pointer:self.next_batch_pointer + self.batch_size]
            self.next_batch_pointer += self.batch_size
        else:
            x_partial_batch_1 = self.images[self.next_batch_pointer:self.num_samples]
            y_partial_batch_1 = self.masks[self.next_batch_pointer:self.num_samples]
            if self.shuffle:
                self.shuffle_samples()
            x_partial_batch_2 = self.images[0:self.batch_size - num_samples_left]
            y_partial_batch_2 = self.masks[0:self.batch_size - num_samples_left]
            x_batch = np.vstack((x_partial_batch_1, x_partial_batch_2))
            y_batch = np.vstack((y_partial_batch_1, y_partial_batch_2))
            self.next_batch_pointer = self.batch_size - num_samples_left
        return x_batch, y_batch

def SemSeg(input_tensor, is_training):
    # TODO: Implement Semantic Segmentation network here
    # Returned logits must be a tensor of size:
    # (None, image_height, image_width, num_classes + 1)
    # 1st dimension is batch dimension
    # image_height and image_width are the height and width of input_tensor
    # last dimension is the softmax dimension. There are 4 texture classes plus 1 background class
    # therefore last dimension will be 5
    # Hint: To make your output tensor has the same height and width with input_tensor,
    # you can use tf.image.resize_bilinear

    height, width, ch, nclass = 196, 196, 3, 5
    
    X = input_tensor 
    # weight initializer
    he_init = tf.contrib.layers.xavier_initializer_conv2d(uniform=True, seed=None, dtype=tf.float32)

    # filter size of 5x5
    ksiz = 5 
    nfilters=8
    nfeatures=10

    ac_fn = tf.nn.relu
    # densenet type connections
    hidden1 = tf.layers.conv2d(X,filters=nfilters,kernel_size=(ksiz,ksiz),padding="same",activation=ac_fn,kernel_initializer=he_init)
    hidden2 = tf.layers.conv2d(tf.concat([X,hidden1],axis=3),filters=nfilters,kernel_size=(ksiz,ksiz),padding="same",activation=ac_fn,kernel_initializer=he_init)
    hidden3 = tf.layers.conv2d(tf.concat([X,hidden1,hidden2],axis=3),filters=nfilters,kernel_size=(ksiz,ksiz),padding="same",activation=ac_fn,kernel_initializer=he_init)
    hidden4 = tf.layers.conv2d(tf.concat([X,hidden1,hidden2,hidden3],axis=3),filters=nfilters,kernel_size=(ksiz,ksiz),padding="same",activation=ac_fn,kernel_initializer=he_init)
    hidden5 = tf.layers.conv2d(tf.concat([X,hidden1,hidden2,hidden3,hidden4],axis=3),filters=nfilters,kernel_size=(ksiz,ksiz),padding="same",activation=ac_fn,kernel_initializer=he_init)
    hidden6 = tf.layers.conv2d(tf.concat([X,hidden1,hidden2,hidden3,hidden4,hidden5],axis=3),filters=nfilters,kernel_size=(ksiz,ksiz),padding="same",activation=ac_fn,kernel_initializer=he_init)
    hidden7 = tf.layers.conv2d(tf.concat([X,hidden1,hidden2,hidden3,hidden4,hidden5,hidden6],axis=3),filters=nfilters,kernel_size=(ksiz,ksiz),padding="same",activation=ac_fn,kernel_initializer=he_init)
    hidden8 = tf.layers.conv2d(tf.concat([X,hidden1,hidden2,hidden3,hidden4,hidden5,hidden6,hidden7],axis=3),filters=nfilters,kernel_size=(ksiz,ksiz),padding="same",activation=ac_fn,kernel_initializer=he_init)
    hidden9 = tf.layers.conv2d(tf.concat([X,hidden1,hidden2,hidden3,hidden4,hidden5,hidden6,hidden7,hidden8],axis=3),filters=nfilters,kernel_size=(ksiz,ksiz),padding="same",activation=ac_fn,kernel_initializer=he_init)

    # feature vectors
    phi = tf.layers.conv2d(tf.concat([X,hidden1,hidden2,hidden3,hidden4,hidden5,hidden6,hidden7,hidden8,hidden9],axis=3),filters=nfeatures,kernel_size=(ksiz,ksiz),padding="same",activation=tf.tanh,kernel_initializer=he_init)

    # logits
    logits = tf.layers.conv2d(phi,filters=nclass,kernel_size=(ksiz,ksiz),padding="same",kernel_initializer=he_init)    
    print(logits.shape)
    return logits


def run():
    # You can tune the hyperparameters here.
    EPOCHS = 17
    BATCH_SIZE = 64
    NUM_ITERS = int(2000 / BATCH_SIZE * EPOCHS)

    train_set = TextureImages('train', batch_size=BATCH_SIZE)
    test_set = TextureImages('test', shuffle=False)

    tf.reset_default_graph()
    x = tf.placeholder(tf.float32, (None, 196, 196, 3))
    y = tf.placeholder(tf.int32, (None, 196, 196, 1))
    one_hot_y = tf.one_hot(y, 5)
    is_training = tf.placeholder(tf.bool, ())

    rate = 0.001
    logits = SemSeg(x, is_training=is_training)
    prediction = tf.argmax(logits, axis=-1)
    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y))
    loss_operation = cross_entropy
    optimizer = tf.train.AdamOptimizer(learning_rate=rate)
    grads_and_vars = optimizer.compute_gradients(loss_operation, tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))
    training_operation = optimizer.apply_gradients(grads_and_vars)

    def evaluation(images, true_labels):
        eval_batch_size = 100
        predicted_labels = []
        for start_index in range(0, len(images), eval_batch_size):
            end_index = start_index + eval_batch_size
            batch_x = images[start_index: end_index]
            batch_predicted_labels = sess.run(prediction, feed_dict={x: batch_x, is_training: False})
            predicted_labels += list(batch_predicted_labels)
        predicted_labels = np.vstack(predicted_labels).flatten()
        true_labels = true_labels.flatten()
        accuracy = float((predicted_labels == true_labels).astype(np.int32).sum()) / true_labels.size
        return predicted_labels, accuracy
    # run takes around 10 minutes, so I load the model instead
    saver = tf.train.Saver()
    sess = tf.Session()
    sess.run(tf.global_variables_initializer())
    
    # training
#     print("Training...")
#     for i in range(NUM_ITERS):
#         batch_x, batch_y = train_set.get_next_batch()
#         _ = sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, is_training: True})
#         if (i + 1) % 50 == 0 or i == NUM_ITERS - 1:
#             _, test_accuracy = evaluation(test_set._images, test_set._masks)
#             print("Iter {}: Test Pixel Accuracy = {:.3f}".format(i, test_accuracy))
#     saver.save(sess, './model')
    # load the model 
    saver.restore(sess, './model')
    print('Evaluating on test set')
    _, test_accuracy = evaluation(test_set._images, test_set._masks)
    print("Test Pixel Accuracy = {:.3f}".format(test_accuracy))
    sess.close()
    return test_accuracy


if __name__ == '__main__':
    run()

