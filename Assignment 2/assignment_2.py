# -*- coding: utf-8 -*-
"""Assignment-2_notebook(real).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10Htney0U5jL4NxgUbh5dVEJSRmHUtG_o

Import and setup some auxiliary functions
"""

from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets
import numpy as np
import timeit
from collections import OrderedDict
from pprint import pformat
import tensorflow as tf


def compute_score(acc, min_thres, max_thres):
    if acc <= min_thres:
        base_score = 0.0
    elif acc >= max_thres:
        base_score = 100.0
    else:
        base_score = float(acc - min_thres) / (max_thres - min_thres) \
                     * 100
    return base_score


def run(algorithm, dataset_name, x_train, y_train, x_valid, y_valid, x_test, y_test):
    start = timeit.default_timer()
    np.random.seed(0)
    predicted_y_test = algorithm(dataset_name, x_train, y_train, x_valid, y_valid, x_test)
    np.random.seed()
    stop = timeit.default_timer()
    run_time = stop - start

    y_test = y_test.flatten()
    predicted_y_test = np.asarray(predicted_y_test).flatten()

    correct_predict = (y_test == predicted_y_test).astype(np.int32).sum()
    incorrect_predict = len(y_test) - correct_predict
    accuracy = float(correct_predict) / len(y_test)

    return (correct_predict, accuracy, run_time)

"""Convenient class for iterating through train set randomly. Onehot convert to convert form for numpy array."""

class DatasetIterator:
    def __init__(self, x, y, batch_size):
        assert len(x) == len(y)
        self.x = x
        self.y = y
        self.b_sz = batch_size
        self.b_pt = 0
        self.d_sz = len(x)
        self.idx = None
        self.randomize()

    def randomize(self):
        self.idx = np.random.permutation(self.d_sz)
        self.b_pt = 0

    def next_batch(self):
        start = self.b_pt
        end = self.b_pt + self.b_sz
        idx = self.idx[start:end]
        x = self.x[idx]
        y = self.y[idx]

        self.b_pt += self.b_sz
        if self.b_pt >= self.d_sz:
            self.randomize()

        return x, y


def one_hot(a, num_classes):
    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])

"""TODO: Implement Logistic Regression here"""

def logistic_regression(dataset_name, x_train, y_train, x_valid, y_valid, x_test):

    if dataset_name == "MNIST":
#         tf.set_random_seed(120)
        batches = 100
        lr = 0.0035
        lam_val = 0.0048

        x = tf.placeholder(dtype = tf.float32, shape = [None, x_train.shape[1]])
        y = tf.placeholder(dtype = tf.float32, shape = [None, 10])
        xMean = np.mean(x_train, axis = 0)
        yMean = np.mean(y_train, axis = 0)
        diff = x - xMean
        W = tf.Variable(tf.random_normal([x_train.shape[1],10]))
#         W = tf.Variable(tf.zeros([x_train.shape[1], 10]))
        pred = tf.matmul(diff, W) + yMean
        # convert predictions to probabilities 
        yp = tf.nn.softmax(pred) 
        # cross entropy loss with L2 regularization 
        loss = -tf.reduce_sum(y * tf.log(yp)) + lam_val * tf.reduce_sum(tf.square(W)) 
#         loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = y, logits = pred)
#         loss += lam_val * tf.reduce_sum(tf.square(W))
        # gradient of loss function
#         optimizer = tf.train.GradientDescentOptimizer(learning_rate = lr).minimize(loss)
        # gradient of loss, update values 
        optimizer = tf.train.AdamOptimizer(learning_rate = lr).minimize(loss)
  
        epoch = 200
        iterator = DatasetIterator(x_train, y_train, batches)
#         iterator = DatasetIterator(x_valid, y_valid, batches)
        with tf.Session() as sess:
          sess.run(tf.global_variables_initializer())
          for i in range(epoch):
            for j in range(batches):
              x_batch, y_batch = iterator.next_batch()
              y_batch = one_hot(y_batch,10)
              sess.run(optimizer, feed_dict={x: x_batch, y: y_batch})
          theta = W.eval() 
          
          yp_test = yp.eval(feed_dict={x: x_test, W: theta})
          # find best labels
          y_test = np.argmax(yp_test, axis = 1)
          
          return y_test
  
    elif dataset_name == "CIFAR10":
#         tf.set_random_seed(120)
        n_inputs = 32 * 32 * 3
        batches = 100
        lr = 0.002
        lam_val = 0.005
        
        x_train = np.reshape(x_train, (x_train.shape[0], n_inputs))
        x_test = np.reshape(x_test, (x_test.shape[0], n_inputs))
#         x_valid = np.reshape(x_valid, (x_valid.shape[0], n_inputs))
#         x_train = tf.reshape(x_train, shape = (x_train.shape[0], -1))
        x = tf.placeholder(dtype = tf.float32, shape = [None, n_inputs])
        y = tf.placeholder(dtype = tf.float32, shape = [None, 10])
        xMean = np.mean(x_train, axis = 0)
        yMean = np.mean(y_train, axis = 0)
        diff = x - xMean
        # start with smaller weights for faster convergence (?)
        W = tf.Variable(tf.random_normal([n_inputs,10])) * 0.1
        pred = tf.matmul(diff, W) + yMean      
        # add a small constant to avoid nan 
        yp = tf.nn.softmax(pred) + 0.00000000001 
#         yp = tf.nn.softmax(pred)
        loss = -tf.reduce_sum(y * tf.log(yp)) + lam_val * tf.reduce_sum(tf.square(W)) 
#         loss = -tf.reduce_sum(y*tf.log(yp)) + lam_val * tf.sqrt(2)/n_inputs
#         loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = y, logits = pred) + lam_val * tf.reduce_sum(tf.square(W))
#         loss += lam_val * tf.reduce_sum(tf.square(W))

        optimizer = tf.train.AdamOptimizer(learning_rate = lr).minimize(loss)

        epoch = 200
        iterator = DatasetIterator(x_train, y_train, batches)
#         iterator = DatasetIterator(x_valid, y_valid, batches)
        with tf.Session() as sess:
          sess.run(tf.global_variables_initializer())
          for i in range(epoch):
            for j in range(batches):
              x_batch, y_batch = iterator.next_batch()
              y_batch = one_hot(y_batch,10)
              sess.run(optimizer, feed_dict={x: x_batch, y: y_batch})

          theta = W.eval() 
          
          yp_test = yp.eval(feed_dict={x: x_test, W: theta})
          # find best label
          y_test = np.argmax(yp_test, axis = 1)
          
          return y_test

"""Main loop. Run time and total score will be shown below."""

def run_on_dataset(dataset_name):
    if dataset_name == "MNIST":
        min_thres = 0.82
        max_thres = 0.92
        mnist = read_data_sets('data', one_hot=False)
        x_train, y_train = (mnist.train._images, mnist.train._labels)
        x_test, y_test = (mnist.test._images, mnist.test.labels)
        
    elif dataset_name == "CIFAR10":
        min_thres = 0.28
        max_thres = 0.38
        cifar10 = tf.keras.datasets.cifar10
        (x_train, y_train), (x_test, y_test) = cifar10.load_data()
    x_valid, y_valid = x_train[-10000:], y_train[-10000:]
    x_train, y_train = x_train[:-10000], y_train[:-10000]

    correct_predict, accuracy, run_time = run(logistic_regression, dataset_name,
                                              x_train, y_train, x_valid, y_valid, x_test, y_test)
    score = compute_score(accuracy, min_thres, max_thres)
    result = OrderedDict(correct_predict=correct_predict,
                         accuracy=accuracy, score=score,
                         run_time=run_time)
    return result, score


def main():
    result_all = OrderedDict()
    score_weights = [0.5, 0.5]
    scores = []
    for dataset_name in ["MNIST", "CIFAR10"]:
        result_all[dataset_name], this_score = run_on_dataset(dataset_name)
        scores.append(this_score)
    total_score = [score * weight for score, weight in zip(scores, score_weights)]
    total_score = np.asarray(total_score).sum().item()
    result_all['total_score'] = total_score
    with open('result.txt', 'w') as f:
        f.writelines(pformat(result_all, indent=4))
    print("\nResult:\n", pformat(result_all, indent=4))


main()

